dataset:
  name: hotpot_qa
  subset: distractor
  split: train
  ingest_limit: 10 # Set to limit dataset size for testing (null = use all). LLM had set it to "null". RRM has set it to 10 for testing.
embedding_model: gemini-embedding-001
llm_model: gpt-4o-mini
vector_store:
  path: ./chroma_db
  collection_name: hotpot_qa_collection_copilot_gpt
  distance_metric: cosine
embedding:
  dimensions: 1024
retrieval:
  top_k_results: 5
  max_context_length: 12000
llm_generation:
  temperature: 0.7
  system_prompt: "You are a helpful assistant that answers questions based on the provided context."
available_embedding_models:
  gemini-embedding-001:
    provider: google
    description: "Google's Gemini embedding model"
    api_key_required: true
    api_key_env: GOOGLE_API_KEY
    dimensions: 1024
  text-embedding-3-small:
    provider: openai
    description: "OpenAI's embedding model"
    api_key_required: true
    api_key_env: OPENAI_API_KEY
    dimensions: 1024
  all-MiniLM-L6-v2:
    provider: chromadb_default
    description: "ChromaDB built-in sentence transformer"
    api_key_required: false
    dimensions: 384
available_llm_models:
  gpt-4o-mini:
    provider: openai
    description: "OpenAI GPT-4o-mini"
    api_key_required: true
    api_key_env: OPENAI_API_KEY
  gemini-1.5-flash:
    provider: google
    description: "Google Gemini 1.5 Flash"
    api_key_required: true
    api_key_env: GOOGLE_API_KEY
  llama3.2:
    provider: ollama
    description: "Meta LLaMA 3.2 (local via Ollama)"
    api_key_required: false
    endpoint: http://localhost:11434/v1
  claude-sonnet-4-20250514:
    provider: anthropic
    description: "Claude Sonnet 4"
    api_key_required: true
    api_key_env: ANTHROPIC_API_KEY